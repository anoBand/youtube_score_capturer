# modules/image_processor.py

import cv2
import io
import numpy as np
import os
from typing import Optional, List


def process_video_frames(
        video_path: str, output_dir: str,
        start_time: Optional[int], end_time: Optional[int],
        x_start: int, x_end: int, y_start: int, y_end: int,
        threshold: float, frame_interval_sec: float = 1.0
) -> List[str]:
    """
    ì˜ìƒì—ì„œ ì•…ë³´ í”„ë ˆì„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    [ê²€ìˆ˜ ë¡œì§ ì ìš©]
    1. í•˜ì´ë¼ì´íŠ¸(ìœ ì±„ìƒ‰) ì˜ì—­ì„ ì™„ë²½íˆ ë§ˆìŠ¤í‚¹í•˜ì—¬ 'ë°°ê²½'ìœ¼ë¡œ ì·¨ê¸‰í•©ë‹ˆë‹¤.
    2. ì´ì „ í”„ë ˆì„ê³¼ í˜„ì¬ í”„ë ˆì„ì˜ í•˜ì´ë¼ì´íŠ¸ ì˜ì—­ì„ í•©ì³ 'ë¹„êµ ì œì™¸ êµ¬ì—­'ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
    3. ìˆœìˆ˜ ì•…ë³´(ê²€ì€ ì‰í¬)ì˜ ë³€í™”ë§Œ ê°ì§€í•˜ì—¬ ì¤‘ë³µì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ Processing: Threshold={threshold}, Interval={frame_interval_sec}s")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise IOError("Cannot open video file.")

    try:
        # 1. ì¢Œí‘œ ì •ê·œí™”
        x_start_p, x_end_p = x_start / 100.0, x_end / 100.0
        y_start_p, y_end_p = y_start / 100.0, y_end / 100.0

        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # 2. íƒìƒ‰ êµ¬ê°„ ì„¤ì •
        current_frame = int(start_time * fps) if start_time else 0
        end_frame = int(end_time * fps) if end_time else total_frames
        frame_step = int(fps * frame_interval_sec) or 1

        processed_image_paths = []

        # [ìƒíƒœ ì €ì¥ ë³€ìˆ˜]
        last_binary_frame = None  # ì´ì „ í”„ë ˆì„ì˜ ì´ì§„í™” ì´ë¯¸ì§€
        last_dilated_mask = None  # ì´ì „ í”„ë ˆì„ì˜ í•˜ì´ë¼ì´íŠ¸ ë§ˆìŠ¤í¬

        MAX_IMAGES = 200

        # [ë§ˆìŠ¤í‚¹ ì»¤ë„ ì„¤ì •]
        # 5x5 ì‚¬ê°í˜• ì»¤ë„: ë…¸ì´ì¦ˆ ì œê±° ë° ì˜ì—­ í™•ì¥ì— ì‚¬ìš©
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))

        while current_frame < end_frame:
            cap.set(cv2.CAP_PROP_POS_FRAMES, current_frame)
            ret, frame = cap.read()
            if not ret: break

            h, w, _ = frame.shape

            # 3. ì‚¬ìš©ì ì§€ì • ì˜ì—­ í¬ë¡­
            cropped = frame[int(h * y_start_p):int(h * y_end_p), int(w * x_start_p):int(w * x_end_p)]
            if cropped.size == 0:
                current_frame += frame_step
                continue

            # =========================================================
            # [ì•Œê³ ë¦¬ì¦˜: Human Check Logic êµ¬í˜„]
            # =========================================================

            # A. ìƒ‰ìƒ ë¶„ë¦¬ (HSV ë³€í™˜)
            hsv = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)
            s_channel = hsv[:, :, 1]  # ì±„ë„
            v_channel = hsv[:, :, 2]  # ëª…ë„

            # B. ì •êµí•œ í•˜ì´ë¼ì´íŠ¸ ë§ˆìŠ¤í¬ ìƒì„±
            # ì¡°ê±´ 1: ì±„ë„ê°€ 10 ì´ìƒ (ì•„ì£¼ ì—°í•œ íŒŒìŠ¤í…”í†¤ë„ ê°ì§€)
            _, s_mask = cv2.threshold(s_channel, 10, 255, cv2.THRESH_BINARY)

            # ì¡°ê±´ 2: ëª…ë„ê°€ 50 ì´ìƒ (ê²€ì€ìƒ‰ ì‰í¬ëŠ” ë§ˆìŠ¤í‚¹í•˜ì§€ ì•Šë„ë¡ ë³´í˜¸)
            _, v_mask = cv2.threshold(v_channel, 50, 255, cv2.THRESH_BINARY)

            # ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•´ì•¼ í•˜ì´ë¼ì´íŠ¸ì„
            color_mask = cv2.bitwise_and(s_mask, v_mask)

            # [ì¶”ê°€] ëª¨í´ë¡œì§€ ë‹«ê¸° (Closing): ë§ˆìŠ¤í¬ ë‚´ë¶€ì˜ êµ¬ë©(ê¸€ì ë“±)ì„ ë©”ì›Œ ë©ì–´ë¦¬ë¡œ ë§Œë“¦
            color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_CLOSE, kernel)

            # C. ë§ˆìŠ¤í¬ íŒ½ì°½ (Dilation): ê²½ê³„ì„  ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•´ ì˜ì—­ì„ ë„“í˜ (3íšŒ ë°˜ë³µ)
            dilated_mask = cv2.dilate(color_mask, kernel, iterations=3)

            # D. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)

            # E. [Inpainting íš¨ê³¼] í•˜ì´ë¼ì´íŠ¸ ìë¦¬ë¥¼ í°ìƒ‰(255)ìœ¼ë¡œ ë®ì–´ì”€
            # -> ì´ ê³¼ì •ìœ¼ë¡œ ì¸í•´ í•˜ì´ë¼ì´íŠ¸ ë°”ëŠ” 'í° ì¢…ì´'ê°€ ë©ë‹ˆë‹¤.
            gray_no_highlight = gray.copy()
            gray_no_highlight[dilated_mask > 0] = 255

            # F. ì´ì§„í™” (Binarization)
            # -> íšŒìƒ‰ì¡° ë…¸ì´ì¦ˆë¥¼ ì—†ì• ê³  0(ìŒí‘œ)ê³¼ 255(ë°°ê²½)ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
            _, binary = cv2.threshold(gray_no_highlight, 200, 255, cv2.THRESH_BINARY)

            # =========================================================

            should_save = False

            if last_binary_frame is None:
                should_save = True
            else:
                # G. ë³€í™”ëŸ‰ ê³„ì‚° (ê²€ìˆ˜ ë¡œì§ì˜ í•µì‹¬)

                # 1. ë‘ ì´ë¯¸ì§€ì˜ ì°¨ì´ ê³„ì‚° (XOR ì—°ì‚°)
                diff = cv2.absdiff(last_binary_frame, binary)

                # 2. [í•µì‹¬] "ê³µí†µ ê°€ì‹œ ì˜ì—­"ë§Œ ë¹„êµ
                # ì´ì „ í”„ë ˆì„ì˜ ë°” ìœ„ì¹˜(last_mask)ì™€ í˜„ì¬ í”„ë ˆì„ì˜ ë°” ìœ„ì¹˜(curr_mask)ë¥¼ í•©ì¹¨
                # ì´ í•©ì³ì§„ ì˜ì—­(unstable_region)ì€ ìŒí‘œê°€ ê°€ë ¤ì¡Œë‹¤ ë‚˜íƒ€ë‚˜ëŠ” ê³³ì´ë¯€ë¡œ ë¹„êµì—ì„œ ì œì™¸
                unstable_region = cv2.bitwise_or(last_dilated_mask, dilated_mask)

                # 3. ë¶ˆì•ˆì • ì˜ì—­ì˜ ì°¨ì´ ê°’ì„ 0ìœ¼ë¡œ ê°•ì œ ì´ˆê¸°í™” (ë¬´ì‹œ)
                diff[unstable_region > 0] = 0

                # 4. ë‚¨ì€ ì˜ì—­(ì•ˆì •ì ì¸ ì•…ë³´)ì—ì„œì˜ ë³€í™”ìœ¨ë§Œ ê³„ì‚°
                diff_score = np.mean(diff)

                # ë””ë²„ê¹…ìš© ë¡œê·¸ (í•„ìš”ì‹œ í•´ì œ)
                # print(f"Frame {current_frame}: Diff Score = {diff_score:.2f}")

                if diff_score > threshold:
                    should_save = True

            if should_save:
                img_path = os.path.join(output_dir, f'frame_{len(processed_image_paths):04d}.png')

                # ì‚¬ìš©ìë¥¼ ìœ„í•´ 'ì›ë³¸(ì»¬ëŸ¬)' ì´ë¯¸ì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
                # (ë¶„ì„ì€ í‘ë°±ìœ¼ë¡œ í–ˆì§€ë§Œ, ê²°ê³¼ë¬¼ì€ ê¹¨ë—í•œ ì›ë³¸ì´ì–´ì•¼ í•¨)
                cv2.imwrite(img_path, cropped)

                processed_image_paths.append(img_path)

                # ë‹¤ìŒ ë¹„êµë¥¼ ìœ„í•´ í˜„ì¬ ìƒíƒœ ì €ì¥
                last_binary_frame = binary
                last_dilated_mask = dilated_mask

                if len(processed_image_paths) >= MAX_IMAGES:
                    print(f"âš ï¸ Reached max image limit ({MAX_IMAGES}). Stopping.")
                    break

            current_frame += frame_step

    except Exception as e:
        print(f"Error during processing: {e}")
        raise e
    finally:
        cap.release()

    print(f"âœ… Extracted {len(processed_image_paths)} images.")
    return processed_image_paths


def get_single_frame_as_bytes(stream_url, time_sec):
    cap = cv2.VideoCapture(stream_url)
    if not cap.isOpened():
        return None
    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    cap.set(cv2.CAP_PROP_POS_FRAMES, int(time_sec * fps))
    ret, frame = cap.read()
    cap.release()
    if ret:
        success, buffer = cv2.imencode('.jpg', frame)
        if success:
            return io.BytesIO(buffer)
    return None