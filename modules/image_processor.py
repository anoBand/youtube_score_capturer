# modules/image_processor.py

import cv2
import io
import numpy as np
import os
from typing import Optional, List


def process_video_frames(
        video_path: str, output_dir: str,
        start_time: Optional[int], end_time: Optional[int],
        x_start: int, x_end: int, y_start: int, y_end: int,
        threshold: float, frame_interval_sec: float = 1.0
) -> List[str]:
    """
    ì˜ìƒì—ì„œ ì•…ë³´ í”„ë ˆì„ì„ ìµœì í™”ëœ ë°©ì‹ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.

    ìµœì í™” í¬ì¸íŠ¸:
    1. cap.set() ëŒ€ì‹  cap.grab()ì„ ì‚¬ìš©í•˜ì—¬ í”„ë ˆì„ ê±´ë„ˆë›°ê¸° ì†ë„ ê°œì„ .
    2. ë§ˆìŠ¤í¬ ì—°ì‚° ì‹œ ë¶ˆí•„ìš”í•œ ë³µì‚¬ë¥¼ ì¤„ì´ê³  ë¹„íŠ¸ ì—°ì‚° ìµœì í™”.
    3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ ëŒ€í˜• ê°ì²´ ì¬ì‚¬ìš©.
    """
    print(f"ğŸš€ Optimized Processing Start: Threshold={threshold}, Interval={frame_interval_sec}s")

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise IOError("Cannot open video file.")

    try:
        # 1. ì¢Œí‘œ ë° ì‹œê°„ ì´ˆê¸° ì„¤ì •
        x_s, x_e = x_start / 100.0, x_end / 100.0
        y_s, y_e = y_start / 100.0, y_end / 100.0

        fps = cap.get(cv2.CAP_PROP_FPS) or 30
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        start_f = int(start_time * fps) if start_time else 0
        end_f = int(end_time * fps) if end_time else total_frames
        frame_step = max(int(fps * frame_interval_sec), 1)

        # ì‹œì‘ ì§€ì ìœ¼ë¡œ ì´ë™ (ìµœì´ˆ 1íšŒëŠ” set ì‚¬ìš©)
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_f)
        current_frame = start_f

        processed_image_paths = []
        last_binary_frame = None
        last_dilated_mask = None

        # Local environment: limit removed
        # MAX_IMAGES = 200
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))

        while current_frame < end_f:
            ret, frame = cap.read()
            if not ret:
                break

            h, w = frame.shape[:2]
            # í¬ë¡­ ì˜ì—­ ê³„ì‚° ë° ìœ íš¨ì„± ê²€ì‚¬
            y1, y2 = int(h * y_s), int(h * y_e)
            x1, x2 = int(w * x_s), int(w * x_e)

            cropped = frame[y1:y2, x1:x2]
            if cropped.size == 0:
                # ë‹¤ìŒ êµ¬ê°„ê¹Œì§€ grab()ìœ¼ë¡œ ê±´ë„ˆë›°ê¸°
                for _ in range(frame_step - 1):
                    cap.grab()
                current_frame += frame_step
                continue

            # =========================================================
            # [ìµœì í™”ëœ ì•Œê³ ë¦¬ì¦˜ ë¡œì§]
            # =========================================================

            # 1. HSV ë³€í™˜ ë° ì±„ë„/ëª…ë„ ê¸°ë°˜ ë§ˆìŠ¤í‚¹ (ë©”ëª¨ë¦¬ ì¬ì‚¬ìš© ê³ ë ¤)
            hsv = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)
            s_channel = hsv[:, :, 1]
            v_channel = hsv[:, :, 2]

            # ì±„ë„ 10 ì´ìƒ & ëª…ë„ 50 ì´ìƒ ì˜ì—­ ì¶”ì¶œ
            _, s_mask = cv2.threshold(s_channel, 10, 255, cv2.THRESH_BINARY)
            _, v_mask = cv2.threshold(v_channel, 50, 255, cv2.THRESH_BINARY)
            color_mask = cv2.bitwise_and(s_mask, v_mask)

            # ëª¨í´ë¡œì§€ ë° íŒ½ì°½ (ì»¤ë„ ì—°ì‚° í†µí•©)
            color_mask = cv2.morphologyEx(color_mask, cv2.MORPH_CLOSE, kernel)
            dilated_mask = cv2.dilate(color_mask, kernel, iterations=2)  # 3íšŒì—ì„œ 2íšŒë¡œ ì¡°ì • (ì„±ëŠ¥)

            # 2. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜ ë° í•˜ì´ë¼ì´íŠ¸ ì œê±°
            gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
            # ë§ˆìŠ¤í¬ ì˜ì—­ì„ í°ìƒ‰ìœ¼ë¡œ ë®ì–´ì”€ (Inpainting ëŒ€ì²´)
            gray[dilated_mask > 0] = 255

            # 3. ì´ì§„í™”
            _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)

            # 4. ë³€í™”ëŸ‰ ê³„ì‚° (XOR ëŒ€ì‹  absdiff ì‚¬ìš© - ì†ë„ë©´ì—ì„œ ìœ ì‚¬í•˜ë‚˜ ì§ê´€ì )
            should_save = False
            if last_binary_frame is None:
                should_save = True
            else:
                diff = cv2.absdiff(last_binary_frame, binary)

                # ê°€ë³€ ì˜ì—­(ë°” ì´ë™ ê²½ë¡œ) ë¬´ì‹œ
                unstable_region = cv2.bitwise_or(last_dilated_mask, dilated_mask)
                diff[unstable_region > 0] = 0

                # í‰ê·  ë³€í™”ëŸ‰ ê³„ì‚° (ì „ì²´ ë©´ì  ëŒ€ë¹„ ë³€í™”ìœ¨)
                diff_score = np.mean(diff)

                if diff_score > threshold:
                    should_save = True

            if should_save:
                img_path = os.path.join(output_dir, f'frame_{len(processed_image_paths):04d}.png')
                cv2.imwrite(img_path, cropped)
                processed_image_paths.append(img_path)

                last_binary_frame = binary
                last_dilated_mask = dilated_mask

                # Local environment: limit removed
                # if len(processed_image_paths) >= MAX_IMAGES:
                #     break

            # í•µì‹¬: ë‹¤ìŒ ë¶„ì„ í”„ë ˆì„ê¹Œì§€ ìˆœì°¨ì ìœ¼ë¡œ grab() í•˜ì—¬ ì†ë„ í–¥ìƒ
            # cap.set()ì„ ë°˜ë³µí•˜ëŠ” ê²ƒë³´ë‹¤ cap.grab()ì´ í”„ë ˆì„ ê°„ê²©ì´ ì§§ì„ ë•Œ í›¨ì”¬ ë¹ ë¦„
            for _ in range(frame_step - 1):
                if not cap.grab():
                    break
            current_frame += frame_step

    except Exception as e:
        print(f"âŒ Error during processing: {e}")
        raise e
    finally:
        cap.release()

    print(f"âœ… Extracted {len(processed_image_paths)} images.")
    return processed_image_paths


def get_single_frame_as_bytes(stream_url, time_sec):
    """ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìœ„í•œ ë‹¨ì¼ í”„ë ˆì„ ì¶”ì¶œ (ìµœì í™”)"""
    cap = cv2.VideoCapture(stream_url)
    if not cap.isOpened():
        return None

    fps = cap.get(cv2.CAP_PROP_FPS) or 30
    target_frame = int(time_sec * fps)

    # íŠ¹ì • ì‹œì ìœ¼ë¡œ í•œ ë²ˆë§Œ ì´ë™
    cap.set(cv2.CAP_PROP_POS_FRAMES, target_frame)
    ret, frame = cap.read()
    cap.release()

    if ret:
        # JPEG ì••ì¶• í’ˆì§ˆ ì¡°ì ˆë¡œ ë„¤íŠ¸ì›Œí¬ ì „ì†¡ ì†ë„ í–¥ìƒ
        success, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
        if success:
            return io.BytesIO(buffer)
    return None